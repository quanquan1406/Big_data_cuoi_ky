import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
# Th√™m nh·ªØng d√≤ng n√†y v√†o ph·∫ßn import tr√™n c√πng
import tensorflow as tf
from tensorflow.keras.models import load_model
import joblib
import json
import numpy as np
# -----------------------------------------------------------
# 1. C·∫§U H√åNH & H√ÄM T·∫¢I D·ªÆ LI·ªÜU
# -----------------------------------------------------------
st.set_page_config(layout="wide", page_title="Bank Stock Analysis Dashboard")

# Custom CSS ƒë·ªÉ l√†m ƒë·∫πp ti√™u ƒë·ªÅ
st.markdown("""
<style>
    .big-font { font-size:20px !important; font-weight: bold; color: #2c3e50; }
</style>
""", unsafe_allow_html=True)

st.title("üìà Dashboard Ph√¢n T√≠ch C·ªï Phi·∫øu Ng√¢n H√†ng")
st.markdown("---")

@st.cache_data
def load_data():
    folder_path = 'data' 
    df_merged = pd.DataFrame()
    
    if not os.path.exists(folder_path):
        return None
        
    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
    for file in files:
        file_path = os.path.join(folder_path, file)
        try:
            df_temp = pd.read_csv(file_path)
            col_date = 'Date' if 'Date' in df_temp.columns else 'Ngay'
            df_temp[col_date] = pd.to_datetime(df_temp[col_date])
            df_temp.set_index(col_date, inplace=True)
            
            ticker = file.split('.')[0].replace('.VN','')
            
            if 'Adj Close' in df_temp.columns:
                df_merged[ticker] = df_temp['Adj Close']
            elif 'Gia_Dieu_Chinh' in df_temp.columns:
                df_merged[ticker] = df_temp['Gia_Dieu_Chinh']
            else:
                df_merged[ticker] = df_temp['Close']
        except:
            continue
            
    df_merged.dropna(inplace=True)
    return df_merged

df = load_data()

if df is None:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'data'.")
    st.stop()

# -----------------------------------------------------------
# 2. SIDEBAR (B·ªò L·ªåC)
# -----------------------------------------------------------
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh d·ªØ li·ªáu")
    all_banks = df.columns.tolist()
    selected_banks = st.multiselect("Ch·ªçn ng√¢n h√†ng:", all_banks, default=all_banks[:5])
    
    start_date = df.index.min()
    end_date = df.index.max()
    date_range = st.date_input("Kho·∫£ng th·ªùi gian:", [start_date, end_date])

if not selected_banks:
    st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 ng√¢n h√†ng.")
    st.stop()

# L·ªçc d·ªØ li·ªáu
df_filtered = df[selected_banks]
df_filtered = df_filtered[(df_filtered.index >= pd.to_datetime(date_range[0])) & 
                          (df_filtered.index <= pd.to_datetime(date_range[1]))]
df_returns = df_filtered.pct_change().dropna()

# -----------------------------------------------------------
# 3. GIAO DI·ªÜN CH√çNH (C√ÅC TAB)
# -----------------------------------------------------------
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìä Xu h∆∞·ªõng & Hi·ªáu su·∫•t", 
    "üìÖ Ph√¢n t√≠ch Chu k·ª≥ (M·ªõi)", 
    "‚ö†Ô∏è R·ªßi ro & Bi·∫øn ƒë·ªông", 
    "üéØ T∆∞∆°ng quan & Ranking",
    "üîÆ D·ª± b√°o t∆∞∆°ng lai"
])

# --- TAB 1: XU H∆Ø·ªöNG & HI·ªÜU SU·∫§T ---
with tab1:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Di·ªÖn bi·∫øn gi√° h√†ng ng√†y")
        st.line_chart(df_filtered, height=400)
        
    with col2:
        st.subheader("üèÜ X·∫øp h·∫°ng TƒÉng tr∆∞·ªüng T·ªïng")
        # T√≠nh t·ªïng tƒÉng tr∆∞·ªüng
        total_return = (df_filtered.iloc[-1] / df_filtered.iloc[0] - 1) * 100
        total_return = total_return.sort_values(ascending=True)
        
        # V·∫Ω b·∫±ng Matplotlib ƒë·ªÉ gi·ªØ m√†u Xanh/ƒê·ªè
        fig_rank, ax_rank = plt.subplots(figsize=(4, 6))
        colors = ['red' if x < 0 else 'green' for x in total_return]
        total_return.plot(kind='barh', color=colors, alpha=0.7, ax=ax_rank)
        ax_rank.set_xlabel("% TƒÉng tr∆∞·ªüng")
        ax_rank.grid(axis='x', linestyle='--', alpha=0.5)
        st.pyplot(fig_rank)

    st.divider()
    
    st.subheader("üìä L·ª£i nhu·∫≠n chi ti·∫øt t·ª´ng nƒÉm (Grouped Bar Chart)")
    
    # 1. Chu·∫©n b·ªã d·ªØ li·ªáu
    yearly_ret = df_filtered.resample('YE').apply(lambda x: x.iloc[-1] / x.iloc[0] - 1) * 100
    yearly_ret.index = yearly_ret.index.year
    
    # Chuy·ªÉn d·ªØ li·ªáu t·ª´ d·∫°ng R·ªông (Wide) sang d·∫°ng D√†i (Long) ƒë·ªÉ v·∫Ω Plotly
    yearly_long = yearly_ret.reset_index().melt(id_vars='Date', var_name='Bank', value_name='Return')
    yearly_long.rename(columns={'Date': 'NƒÉm', 'Bank': 'Ng√¢n h√†ng', 'Return': 'L·ª£i nhu·∫≠n (%)'}, inplace=True)
    
    # 2. V·∫Ω b·∫±ng Plotly Express
    import plotly.express as px
    
    fig_grouped = px.bar(
        yearly_long, 
        x="NƒÉm", 
        y="L·ª£i nhu·∫≠n (%)", 
        color="Ng√¢n h√†ng", 
        barmode="group",  # <--- QUAN TR·ªåNG: L·ªánh n√†y gi√∫p c√°c c·ªôt ƒë·ª©ng c·∫°nh nhau
        text_auto='.1f',  # Hi·ªÉn th·ªã s·ªë tr√™n ƒë·∫ßu c·ªôt (1 ch·ªØ s·ªë th·∫≠p ph√¢n)
        color_discrete_sequence=px.colors.qualitative.Prism # Ch·ªçn b·∫£ng m√†u ƒë·∫πp, r√µ r√†ng
    )
    
    # Tinh ch·ªânh giao di·ªán bi·ªÉu ƒë·ªì
    fig_grouped.update_layout(
        xaxis=dict(tickmode='linear'), # ƒê·∫£m b·∫£o hi·ªán ƒë·ªß c√°c nƒÉm 2020, 2021...
        legend_title_text='M√£ CP',
        height=500
    )
    
    # Hi·ªÉn th·ªã l√™n Streamlit
    st.plotly_chart(fig_grouped, use_container_width=True)

# --- TAB 2: PH√ÇN T√çCH CHU K·ª≤ (M·ªöI) ---
with tab2:
    st.header("üîç Hi·ªáu ·ª©ng M√πa v·ª• (Seasonality)")
    st.markdown("Bi·ªÉu ƒë·ªì n√†y cho bi·∫øt l·ª£i nhu·∫≠n trung b√¨nh c·ªßa c√°c ng√¢n h√†ng theo t·ª´ng th√°ng trong nƒÉm.")
    
    # T√≠nh trung b√¨nh theo th√°ng
    df_temp_ret = df_returns.copy()
    df_temp_ret['Month'] = df_temp_ret.index.month
    monthly_seasonality = df_temp_ret.groupby('Month').mean() * 100 # Ra %
    
    # V·∫Ω bi·ªÉu ƒë·ªì
    st.bar_chart(monthly_seasonality)
    
    st.info("üí° **G·ª£i √Ω:** N·∫øu c·ªôt th√°ng 1, 2 cao -> C√≥ hi·ªáu ·ª©ng tƒÉng gi√° d·ªãp T·∫øt. N·∫øu th√°ng 5 th·∫•p -> Hi·ªáu ·ª©ng 'Sell in May'.")

# --- TAB 3: R·ª¶I RO ---
with tab3:
    col_risk1, col_risk2 = st.columns(2)
    
    with col_risk1:
        st.subheader("Ph√¢n ph·ªëi l·ª£i nhu·∫≠n (Boxplot)")
        fig_box, ax_box = plt.subplots()
        sns.boxplot(data=df_returns * 100, ax=ax_box, palette="Set3")
        ax_box.set_ylabel("L·ª£i nhu·∫≠n ng√†y (%)")
        st.pyplot(fig_box)
        
    with col_risk2:
        st.subheader("M·ª©c s·ª•t gi·∫£m k·ª∑ l·ª•c (Max Drawdown)")
        rolling_max = df_filtered.cummax()
        drawdown = df_filtered / rolling_max - 1.0
        st.area_chart(drawdown)

# --- TAB 4: T∆Ø∆†NG QUAN ---
with tab4:
    col_corr1, col_corr2 = st.columns([1, 1])
    
    with col_corr1:
        st.subheader("Ma tr·∫≠n t∆∞∆°ng quan")
        fig_corr, ax_corr = plt.subplots(figsize=(8, 8))
        sns.heatmap(df_returns.corr(), annot=True, cmap='coolwarm', fmt=".2f", ax=ax_corr)
        st.pyplot(fig_corr)
        
    with col_corr2:
        st.subheader("R·ªßi ro vs L·ª£i nhu·∫≠n")
        rets = df_returns.mean() * 252
        risk = df_returns.std() * (252 ** 0.5)
        
        fig_scat, ax_scat = plt.subplots(figsize=(8, 8))
        ax_scat.scatter(risk, rets, s=100, c='teal', alpha=0.6)
        for label, x, y in zip(rets.index, risk, rets):
            ax_scat.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', ha='center', weight='bold')
        ax_scat.set_xlabel("R·ªßi ro (Volatility)")
        ax_scat.set_ylabel("L·ª£i nhu·∫≠n (Return)")
        ax_scat.grid(True, linestyle='--')
        st.pyplot(fig_scat)

# --- TAB 5: D·ª∞ B√ÅO AI (M·ªöI) ---
with tab5:
    st.header("ü§ñ M√¥ h√¨nh D·ª± b√°o Gi√° (LSTM)")
    
    # 1. Ch·ªçn ng√¢n h√†ng c·∫ßn d·ª± b√°o (Ch·ªâ l·∫•y ng√¢n h√†ng ƒë·∫ßu ti√™n trong list ƒë√£ ch·ªçn)
    target_bank = selected_banks[0]
    st.info(f"ƒêang ch·∫°y m√¥ h√¨nh d·ª± b√°o cho m√£: **{target_bank}**")
    
    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file m√¥ h√¨nh (C·∫•u tr√∫c: Save_model/ACB.VN/...)
    # L∆∞u √Ω: Th√™m ƒëu√¥i .VN n·∫øu t√™n th∆∞ m·ª•c c·ªßa b·∫°n c√≥ .VN
    model_folder = f"Save_model/{target_bank}.VN" 
    
    model_path = os.path.join(model_folder, "LSTM.h5")
    scaler_path = os.path.join(model_folder, "LSTM_scaler.pkl")
    loss_path = os.path.join(model_folder, "model_loss.json")
    
    # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng
    if os.path.exists(model_path) and os.path.exists(scaler_path):
        try:
            # --- LOAD M√î H√åNH ---
            model = load_model(model_path)
            scaler = joblib.load(scaler_path)
            
            
            # --- HI·ªÇN TH·ªä ƒê√ÅNH GI√Å M√î H√åNH (METRICS) ---
            col_ai1, col_ai2 = st.columns([1, 1]) # Chia ƒë√¥i m√†n h√¨nh
            
            with col_ai1:
                st.subheader("üìä Hi·ªáu qu·∫£ m√¥ h√¨nh (Evaluation Metrics)")
                
                if os.path.exists(loss_path):
                    with open(loss_path, 'r') as f:
                        metrics_data = json.load(f)
                    
                    # File json c·ªßa b·∫°n c√≥ d·∫°ng: {"LSTM": {"rmse": ..., "mae": ..., "r2": ...}}
                    if "LSTM" in metrics_data:
                        data = metrics_data["LSTM"]
                        
                        # Hi·ªÉn th·ªã 3 ch·ªâ s·ªë quan tr·ªçng
                        m1, m2, m3 = st.columns(3)
                        
                        with m1:
                            st.metric(label="R2 Score (ƒê·ªô ph√π h·ª£p)", 
                                      value=f"{data.get('r2', 0):.4f}", 
                                      help="C√†ng g·∫ßn 1 c√†ng t·ªët")
                        
                        with m2:
                            st.metric(label="RMSE (Sai s·ªë)", 
                                      value=f"{data.get('rmse', 0):.0f}", 
                                      help="C√†ng th·∫•p c√†ng t·ªët")
                                      
                        with m3:
                            st.metric(label="MAE (Sai s·ªë tuy·ªát ƒë·ªëi)", 
                                      value=f"{data.get('mae', 0):.0f}")
                        
                        # ƒê√°nh gi√° b·∫±ng l·ªùi vƒÉn
                        r2 = data.get('r2', 0)
                        if r2 > 0.9:
                            st.success("‚úÖ M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c R·∫§T CAO (>90%)")
                        elif r2 > 0.7:
                            st.info("‚ÑπÔ∏è M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c KH√Å (>70%)")
                        else:
                            st.warning("‚ö†Ô∏è M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c TH·∫§P. C·∫ßn train l·∫°i.")
                            
                    else:
                        st.warning("File JSON kh√¥ng ch·ª©a key 'LSTM'.")
                        st.json(metrics_data) # In file ra ƒë·ªÉ debug n·∫øu c·∫ßn
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y file model_loss.json")

            # --- TH·ª∞C HI·ªÜN D·ª∞ B√ÅO ---
            with col_ai2:
                st.subheader("üîÆ D·ª± b√°o ng√†y ti·∫øp theo")
                
                # L·∫•y d·ªØ li·ªáu 60 ng√†y g·∫ßn nh·∫•t c·ªßa m√£ ƒë√≥ ƒë·ªÉ d·ª± b√°o
                # QUAN TR·ªåNG: time_step ph·∫£i kh·ªõp v·ªõi l√∫c b·∫°n train m√¥ h√¨nh (th∆∞·ªùng l√† 60)
                time_step = 60 
                
                # L·∫•y d·ªØ li·ªáu gi√° ƒë√≥ng c·ª≠a (ho·∫∑c gi√° ƒëi·ªÅu ch·ªânh t√πy l√∫c train b·∫°n d√πng c·ªôt n√†o)
                # ·ªû ƒë√¢y gi·∫£ s·ª≠ b·∫°n train b·∫±ng c·ªôt Adj Close (Gia_Dieu_Chinh)
                data_last_60 = df[target_bank].values[-time_step:]
                
                # Reshape v√† Scale d·ªØ li·ªáu
                data_last_60 = data_last_60.reshape(-1, 1)
                data_scaled = scaler.transform(data_last_60)
                
                # Reshape cho ƒë√∫ng input c·ªßa LSTM (1, 60, 1)
                X_input = data_scaled.reshape(1, time_step, 1)
                
                # D·ª± b√°o
                pred_scaled = model.predict(X_input)
                pred_price = scaler.inverse_transform(pred_scaled)[0][0]
                
                # L·∫•y gi√° ng√†y g·∫ßn nh·∫•t ƒë·ªÉ so s√°nh
                last_price = df[target_bank].iloc[-1]
                change = pred_price - last_price
                pct_change = (change / last_price) * 100
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ki·ªÉu s·ªë l·ªõn (Metric)
                st.metric(
                    label=f"Gi√° d·ª± b√°o ng√†y mai ({target_bank})",
                    value=f"{pred_price:,.0f} VND",
                    delta=f"{change:,.0f} VND ({pct_change:.2f}%)"
                )
                
                st.write(f"Gi√° ƒë√≥ng c·ª≠a g·∫ßn nh·∫•t: **{last_price:,.0f} VND**")
                
                if pct_change > 0:
                    st.success("M√¥ h√¨nh d·ª± b√°o: **TƒÇNG** üöÄ")
                else:
                    st.error("M√¥ h√¨nh d·ª± b√°o: **GI·∫¢M** üìâ")

        except Exception as e:
            st.error(f"L·ªói khi ch·∫°y m√¥ h√¨nh: {e}")
            st.warning("G·ª£i √Ω: Ki·ªÉm tra xem 'time_step' (s·ªë ng√†y l√πi l·∫°i) trong code dashboard c√≥ kh·ªõp v·ªõi l√∫c b·∫°n train m√¥ h√¨nh kh√¥ng?")
            
    else:
        st.warning(f"‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y m√¥ h√¨nh ƒë√£ l∆∞u cho m√£ **{target_bank}**.")
        st.write(f"Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c: `{model_folder}`")
        st.write("C·∫•u tr√∫c file c·∫ßn thi·∫øt: `LSTM.h5`, `LSTM_scaler.pkl`")